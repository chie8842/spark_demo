{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MatrixFactorizationモデルを用いたレコメンデーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# 本来は訓練データと評価データを分けるべきだが、\n",
    "# MatrixFactorizationモデルの場合、分けることが難しいので、\n",
    "# 訓練データと評価データは同じものを使用している。\n",
    "\n",
    "# データの読み込み\n",
    "ratings_csv = \"s3:/chie8842_spark_demo/movielens/ratings.csv\"\n",
    "ratings = spark.read.csv(ratings_csv, header=\"true\")\n",
    "\n",
    "# モデル学習のインプットの型はInt型なので、\n",
    "# String型をInt型の一意なIDに変換してくれるStirngIndexerを使う。\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\")\n",
    "            .fit(ratings) for column in [\"userId\", \"movieId\", \"rating\"] ]\n",
    "\n",
    "# ALSのパラメータ設定\n",
    "als = ALS(\n",
    "    rank=40,\n",
    "    maxIter=10,\n",
    "    seed=0,\n",
    "    userCol=\"userId_index\",\n",
    "    itemCol=\"movieId_index\",\n",
    "    ratingCol=\"rating_index\")\n",
    "\n",
    "indexers.append(als)\n",
    "\n",
    "# パイプラインで処理を実行する\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "\n",
    "# モデルの学習\n",
    "model = pipeline.fit(ratings)\n",
    "\n",
    "#  モデルによるrating値の予測\n",
    "predictions = model.transform(ratings)\n",
    "\n",
    "# rmseによるモデルの評価\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating_index\", \n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, explode\n",
    "\n",
    "# 全ユーザに対して予測値の高いmovieを10個レコメンドする\n",
    "pre_predicted = (model\n",
    "                 .stages[-1]\n",
    "                 .recommendForAllUsers(10)\n",
    "                 .select(\n",
    "                     \"userId_index\"\n",
    "                     ,explode(\"recommendations\").alias(\"exploded\")))\n",
    "predicted = (pre_predicted\n",
    "             .select(\"userId_index\"\n",
    "                     , pre_predicted.exploded.movieId_index.alias(\"movieId_index\")\n",
    "                     , pre_predicted.exploded.rating.alias(\"rating\")))\n",
    "\n",
    "\n",
    "predicted.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
